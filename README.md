# Data Engineering Portfolio

## Project: Simple Data Pipeline and ETL Process

### Overview
This project demonstrates a simple data pipeline and ETL process using Python and SQL. It includes:
- A Python script (`data_pipeline.py`) to process data and save the output.
- An SQL script (`etl_process.sql`) to simulate an ETL process.
- A `requirements.txt` file listing the required Python libraries.

### Tools Used
- Python
- Pandas (for data processing)
- SQL (for ETL process)

### Steps to Run
1. Clone this repository.
2. Install dependencies: `pip install -r requirements.txt`.
3. Run the Python script: `python data_pipeline.py`.
4. Execute the SQL script in your SQL environment (e.g., MySQL, PostgreSQL).

### Results
- The Python script generates a file named `processed_data.csv`.
- The SQL script creates tables and performs transformations on the data.

### Screenshots
![Sample Output](screenshots/sample_output.png)
